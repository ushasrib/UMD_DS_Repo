{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c010436e",
   "metadata": {},
   "source": [
    "#### 04/20/24 update: In this notebook using Morocco files from WVS, Afro and Arab Barometers, we created 3 tables. \n",
    "- added response types column to the survey_questions table along with category type\n",
    "\n",
    "**Summary**\n",
    "This code creates 3 tables, dimension_value_Morocco, survey_questions_Morocco and response_values_Morocco, in survey_questions_Morocco we have added response_types column as well as category column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b733dc58",
   "metadata": {
    "id": "b733dc58",
    "outputId": "03295d28-6696-4f5a-ac1b-ac9eb2501313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of response types in WVS_Wave_7_Morocco: 420\n",
      "Number of response types in Afrobarometer_Morocco: 347\n",
      "Number of response types in Arab_barometer_Morocco: 430\n",
      "1197\n",
      "Created a mapping dataframe with 1256 q_id to response_types mapping from 3 files\n"
     ]
    }
   ],
   "source": [
    "#This code picks up question ids and corresponding range of responses using pandas value_labels() method on stata and spss files\n",
    "#It then creates Unique identifiers for response types by grouping similar response_types\n",
    "#It also creates a dataframe with all the Question to reponse_type mappings \n",
    "\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#Defining functions to return value labels from stata and spss files\n",
    "def get_value_labels_stata(source_file):\n",
    "    stata_iterator = pd.read_stata(source_file, iterator=True)\n",
    "    return stata_iterator.value_labels()\n",
    "\n",
    "def get_value_labels_spss(source_file):\n",
    "    df, meta = pyreadstat.read_sav(source_file)\n",
    "    return meta.variable_value_labels\n",
    "\n",
    "#Our 9 source files downloaded from different barometers, source names derived from source files\n",
    "source_files = { 'WVS_Wave_7_Morocco_Stata_v5.0.dta': 'WVS_Wave_7_Morocco',\n",
    "                  'MOR_R9.data_.final_.wtd_release.14Feb23.sav': 'Afrobarometer_Morocco',\n",
    "                  \"AB7_ENG_Release_Version6.dta\": 'Arab_barometer_Morocco'}\n",
    "number_of_files = len(source_files)\n",
    "response_types = {}\n",
    "num_response_types_total = 0\n",
    "unique_response_types = set()\n",
    "count_q_id = 0\n",
    "\n",
    "q_id_mapping_list = []\n",
    "\n",
    "for source_file, source_name in source_files.items():\n",
    "    # Assigning value labels from different source files to a variable\n",
    "    if source_file.endswith('.dta'):\n",
    "\n",
    "        x = get_value_labels_stata(source_file)\n",
    "        df_source_file = pd.read_stata(source_file, convert_categoricals=False)\n",
    "        df_source_file.columns = df_source_file.columns.str.lower()\n",
    "\n",
    "    elif source_file.endswith('.sav'):\n",
    "\n",
    "        x =  get_value_labels_spss(source_file)\n",
    "        df_source_file, meta = pyreadstat.read_sav(source_file)\n",
    "        df_source_file.columns = df_source_file.columns.str.lower()\n",
    "    \n",
    "    # Counting number of response types for the current source file\n",
    "    num_response_types = len(x)\n",
    "    num_response_types_total += num_response_types\n",
    "\n",
    "    # Printing number of response types in the current source file\n",
    "    print(f\"Number of response types in {source_name}: {num_response_types}\")\n",
    "    questions_source_file =[]\n",
    "    # Iterating through the value labels dictionary obtaining q_ids and answers\n",
    "    for q_id, answers in x.items():\n",
    "        q_id = q_id.lower()\n",
    "       \n",
    "        count_q_id += 1\n",
    "        response_type = None\n",
    "        #checking if answers already exist in the response_types dict and if they do, assigning to a pre-existing rt_id\n",
    "        for rt_id, rt_answers in response_types.items():\n",
    "            if rt_answers['answers'] == answers:\n",
    "                response_type = rt_id\n",
    "                break\n",
    "\n",
    "        # If response type doesn't exist, creating a new one\n",
    "        if response_type is None:\n",
    "            response_type = 'RT{}'.format(len(response_types)+1)\n",
    "            response_types[response_type] = {\n",
    "                'answers': answers,\n",
    "                'source_name': source_name,\n",
    "                'inferred_RT': 0  \n",
    "            }\n",
    "            \n",
    "        # Adding (q_id, response_type) pair to the mapping list\n",
    "        q_id_mapping_list.append((q_id, source_name, response_type))\n",
    "        questions_source_file.append(q_id)    \n",
    "        #print(\"Question {} from source_name {} is assigned to response type {}\".format(q_id, source_name, response_type))\n",
    "    df_source_file_columns = df_source_file.columns.str.lower()\n",
    "    for column in df_source_file_columns:\n",
    "        if all(column != q_id for q_id in questions_source_file):\n",
    "            unique_values = df_source_file[column].unique().tolist()\n",
    "\n",
    "            # Create a dictionary encoding the values with numerical keys\n",
    "            value_encoding = {i+1: val for i, val in enumerate(unique_values)}\n",
    "            response_type = 'RT{}'.format(len(response_types)+1)\n",
    "            response_types[response_type] = {\n",
    "            'answers': value_encoding,\n",
    "            'source_name': source_name,\n",
    "            'inferred_RT': 1  \n",
    "                }\n",
    "            \n",
    "            q_id_mapping_list.append((column, source_name, response_type))    \n",
    "\n",
    "        # Add to unique_response_types set\n",
    "        unique_response_types.add(response_type)\n",
    "        \n",
    "#Creating a mapping dataframe to merge with survey_questions dataframe\n",
    "mapping_df_morocco = pd.DataFrame(q_id_mapping_list, columns = ['q_id', 'source_name', 'response_type'])\n",
    "\n",
    "print(count_q_id)\n",
    "\n",
    "print(f'Created a mapping dataframe with {len(mapping_df_morocco)} q_id to response_types mapping from {number_of_files} files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264e7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print([mapping_df_Morocco[mapping_df_Morocco['q_id']== 'q111']])\n",
    "#print([mapping_df_Morocco[mapping_df_Morocco['q_id']== 'q112']])\n",
    "#Counting duplicate q_ids\n",
    "#duplicate_q_id_counts = mapping_df_Morocco['q_id'].value_counts()\n",
    "#print(duplicate_q_id_counts[duplicate_q_id_counts>1])\n",
    "\n",
    "# duplicate_count = mapping_df_morocco.duplicated(subset=['q_id']).sum()\n",
    "# print(\"Number of duplicate q_ids:\", duplicate_count)\n",
    "# print(mapping_df_morocco.duplicated(subset=['q_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd5340e",
   "metadata": {
    "id": "edd5340e",
    "outputId": "88108baa-9173-4bcc-de6d-5a5a2318a7fe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dimension_value_morocco table in postgres database with 44073 rows\n"
     ]
    }
   ],
   "source": [
    "#This code creates the dimension_value table with response type, label, code and source name\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "rows = []\n",
    "\n",
    "\n",
    "# Iterating over response_types dictionary created in previous code\n",
    "for response_type, data in response_types.items():\n",
    "    answers = data['answers']\n",
    "    source_name = data['source_name']\n",
    "    inferred_RT = data['inferred_RT']\n",
    "\n",
    "        \n",
    "    # Iterating over each response and its value\n",
    "    for response_code, response_label in answers.items():\n",
    "        row = {\n",
    "            'response_type': response_type,\n",
    "            'response_label': response_label,\n",
    "            'response_code': response_code,\n",
    "            'source_name': source_name,\n",
    "            'inferred_RT': inferred_RT\n",
    "          \n",
    "        }\n",
    "        # Appendings rows to rows list\n",
    "        rows.append(row)\n",
    "    \n",
    "\n",
    "# Creating a pandas DataFrame from the list of rows\n",
    "dimension_value_df_Morocco = pd.DataFrame(rows)\n",
    "\n",
    "#Creating dimension_value postgres table from dataframe\n",
    "connection_str = 'postgresql://postgres:Capstone@localhost/ics_capstone'\n",
    "engine = create_engine(connection_str)\n",
    "table_name = 'dimension_value_morocco'\n",
    "\n",
    "dimension_value_df_Morocco.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "print(f'Created dimension_value_morocco table in postgres database with {len(dimension_value_df_Morocco)} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f9295d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of variable labels for WVS_Wave_7_Morocco: 430\n",
      "Length of variable labels for Afrobarometer_Morocco: 373\n",
      "Length of variable labels for Arab_barometer_Morocco: 453\n",
      "No of rows in merged dataframe sq_rt_df_morocco is 1256\n",
      "Out of 1256 rows from 3 files, inserted 1256 rows into the 'survey_questions_morocco' table in postgres database.\n"
     ]
    }
   ],
   "source": [
    "# This code extracts variable labels from stata and spss files to create a survey questions dataframe\n",
    "# The mapping dataframe created in previous code is merged with the survey questions data frame\n",
    "#survey_questions table is created from the merged dataframes\n",
    "\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "source_files = { 'WVS_Wave_7_Morocco_Stata_v5.0.dta': 'WVS_Wave_7_Morocco',\n",
    "                  'MOR_R9.data_.final_.wtd_release.14Feb23.sav': 'Afrobarometer_Morocco',\n",
    "                  \"AB7_ENG_Release_Version6.dta\": 'Arab_barometer_Morocco'}\n",
    "\n",
    "number_of_files = len(source_files)\n",
    "\n",
    "#Creating functions to return variable labels\n",
    "def get_variable_labels_stata(source_file):\n",
    "    stata_iterator = pd.read_stata(source_file, iterator=True)\n",
    "    return stata_iterator.variable_labels()\n",
    "\n",
    "def get_variable_labels_spss(source_file):\n",
    "    df, meta = pyreadstat.read_sav(source_file)\n",
    "    variable_labels = {}\n",
    "    for column_name, label in zip(meta.column_names, meta.column_labels):\n",
    "        variable_labels[column_name] = label\n",
    "    return variable_labels\n",
    "\n",
    "rows = []\n",
    "total_rows = 0\n",
    "category_var = 1\n",
    "\n",
    "demographic_keywords = ['age', 'birth', 'denomination', 'respondent',\n",
    "                        \"respondent's\", \"interviewer\", \"interviewr's\"\n",
    "                       ]\n",
    "#Arab Demographic survey is segregated into separate core demographic and demographic sections\n",
    "#There were no unique keyword identifiers for demographics, closest was household but some psychographic Qs had this word\n",
    "#Hence we took the question nos directly\n",
    "Arab_demographic_questions = [\"ID\", \"DATE\", \"PSU\", \"Q1 Governorate\", \"Q13\", \"Q1A_PAL\", \"Q1A_ALG\", \"Q1A_LIB\",\n",
    "                        \"Q1001\", \"Q1001YEAR\", \"Q1001APPROX\",\"Q1002\",\"Q1001A\",\"Q1003\",\"Q1010\",\n",
    "                        \"Q1005\",\"Q1005B\",\"Q1006\",\"Q1006A\",\"Q1021\",\n",
    "                        \"Q1010B2\",\"Q1014A\", \"Q1014B\",\"Q1014C\",\"Q1015\",\"Q1015A\",\"Q1016\"\n",
    "                        ]\n",
    "for source_file, source_name in source_files.items():\n",
    "    # assigning variable labels from the source file to a variable\n",
    "    if source_file.endswith('.dta'):\n",
    "        x = get_variable_labels_stata(source_file)\n",
    "    elif source_file.endswith('.sav'):\n",
    "        x = get_variable_labels_spss(source_file)\n",
    "    num_rows = len(x)    \n",
    "    print(f\"Length of variable labels for {source_name}: {num_rows}\")\n",
    "    total_rows += num_rows\n",
    "        \n",
    "    # Extracting variable labels and appending them to the rows list\n",
    "    for q_id, q_text in x.items():\n",
    "        q_id = q_id.lower()\n",
    "        lowercase_q_text = q_text.lower()\n",
    "        category_var = 1\n",
    "        if source_name == 'Arab_barometer_Morocco' and q_id in Arab_demographic_questions:\n",
    "            category_var = 0\n",
    "        else:    \n",
    "            if source_name != 'Arab_barometer_Morocco':\n",
    "                \n",
    "                lowercase_q_text = q_text.lower()\n",
    "                if not q_id.startswith('q'):\n",
    "                    category_var = 0 #meaning not psycographic\n",
    "                if not q_id[1].isdigit():\n",
    "                    category_var = 0 #meaning not psycographic\n",
    "                if any(re.search(r'\\b{}\\b'.format(re.escape(keyword)), lowercase_q_text) for keyword in demographic_keywords):    \n",
    "                    category_var = 0 #meaning not psycographic\n",
    "\n",
    "        row = {'source_name': source_name, 'q_id': q_id, 'q_text': q_text, 'category': category_var}\n",
    "        rows.append(row)\n",
    "\n",
    "# Creating an initial DataFrame from the list of rows\n",
    "survey_questions_df_morocco = pd.DataFrame(rows)\n",
    "#duplicate_count_sq = survey_questions_df.duplicated(subset=['q_id']).sum()\n",
    "#print(\"Number of duplicate q_ids in survey_questions table are:\", duplicate_count_sq)\n",
    "\n",
    "# null_counts_sq = survey_questions_df.isnull().sum()\n",
    "# print(f'Nulls in survey_questions_df are {null_counts_sq}')\n",
    "\n",
    "\n",
    "#merging mapping_df from previous code to include response_types\n",
    "sq_rt_df_morocco = pd.merge(survey_questions_df_morocco, mapping_df_morocco, on=['q_id','source_name'], how='left')\n",
    "print(f'No of rows in merged dataframe sq_rt_df_morocco is {len(sq_rt_df_morocco)}')\n",
    "# null_counts_sq_rt = sq_rt_df.isnull().sum()\n",
    "# print(f'Nulls in merged sq_rt_df are {null_counts_sq_rt}')\n",
    "\n",
    "\n",
    "\n",
    "#Creating survey_questions postgres table from merged dataframe\n",
    "connection_string = 'postgresql://postgres:Capstone@localhost/ics_capstone'\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "table_name = 'survey_questions_morocco'\n",
    "\n",
    "# Inserting the DataFrame into the PostgreSQL table\n",
    "sq_rt_df_morocco.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "print(f\"Out of {total_rows} rows from {number_of_files} files, inserted {len(sq_rt_df_morocco)} rows into the '{table_name}' table in postgres database.\")\n",
    "#print(f'There are {null_counts_sq_rt} Nulls in the response_types column in the survey_questions table as q_ids are not the same in value labels and variable labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35458ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched q_ids in survey_questions dataframe are: 0\n"
     ]
    }
   ],
   "source": [
    "#This code finds number of unmatched **q_ids only**from mapping_df and survey_questions dataframe\n",
    "import pandas as pd\n",
    "\n",
    "#unmatched_survey_qids = set(survey_questions_df[survey_questions_df[['q_id']].lower()) - set(mapping_df[mapping_df[['q_id']].lower())\n",
    "unmatched_survey_qids_morocco = set(survey_questions_df_morocco['q_id']) - set(mapping_df_morocco['q_id'])\n",
    "print(f'Number of unmatched q_ids in survey_questions dataframe are: {len(unmatched_survey_qids_morocco)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9bfa352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12811362, 4)\n",
      "Created the response_values_morocco table in postgres with 12811362 rows.\n"
     ]
    }
   ],
   "source": [
    "#This code updates the actual survey responses from respondents into a postgres table\n",
    "#If we ran this code for all the files, we are receiving memory error in our laptops. \n",
    "#Therefore, we ran this code for one stata and one spss files and created the table successfully\n",
    "\n",
    "source_files = { 'WVS_Wave_7_Morocco_Stata_v5.0.dta': 'WVS_Wave_7_Morocco',\n",
    "                  'MOR_R9.data_.final_.wtd_release.14Feb23.sav': 'Afrobarometer_Morocco',\n",
    "                  \"AB7_ENG_Release_Version6.dta\": 'Arab_barometer_Morocco'}\n",
    "# \"Latinobarometro_2023_Eng_Stata_v1_0.dta\": \"Latinobarometro_2023_Eng_Stata_v1_0.dta\",\n",
    "#     \"ZA7781_v2-0-0.dta\": \"Eurobarometer_v2-0-0.dta\",\n",
    "#     \"AB7_ENG_Release_Version6.dta\": \"Arab_barometer_ENG_Release_Version6.dta\",\n",
    "#     \"USA_2023_LAPOP_AmericasBarometer_v1.0_w.dta\": \"USA_2023_LAPOP_AmericasBarometer_v1.0_w.dta\",\n",
    "#     \"Caucasus_CB_2017_Georgia_public_17.11.17.dta\": \"Caucasus_CB_2017_Georgia_public_17.11.17.dta\",\n",
    "#     \"central-asia-barometer-survey-wave-1-stata-kyrgyzstan-2017-spring.dta\": \"central-asia-barometer-survey-wave-1-stata-kyrgyzstan-2017-spring.dta\",\n",
    "#     \"SAF_R9.data_.final_.wtd_release.30May23.sav\": \"SouthAfrica.data_30May23.sav\",\n",
    "#     \"20230504_W5_merge_15.dta\": \"All_Asian_Countries_W5_merge_15.dta\"\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Creating dataframes with actual survey responses from stata and spss tables\n",
    "for source_file, source_name in source_files.items():\n",
    "   \n",
    "    if source_file.endswith('.dta'):\n",
    "\n",
    "        df = pd.read_stata(source_file, convert_categoricals=False)\n",
    "\n",
    "    elif source_file.endswith('.sav'):\n",
    "\n",
    "        df, meta =  pyreadstat.read_sav(source_file)\n",
    "       \n",
    "    \n",
    "    # Iterating through the rows of the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        for column in df.columns:\n",
    "                q_id = column\n",
    "                q_id = q_id.lower()\n",
    "                response = row[column]\n",
    "                respondent_id = index+1  # Using the index as the respondent_id\n",
    "\n",
    "                data.append({'respondent_id': respondent_id, 'q_id': q_id, 'response': response, 'source_name': source_name})\n",
    "           \n",
    "df_combined = pd.DataFrame(data)\n",
    "print(df_combined.shape)\n",
    "connection_str = 'postgresql://postgres:Capstone@localhost/ics_capstone'\n",
    "engine = create_engine(connection_str)\n",
    "table_name = 'response_values_morocco'        \n",
    "df_combined.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "print(f\"Created the {table_name} table in postgres with {len(df_combined)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f925f986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
